{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_eng2deutch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272h1ufI6HS2"
      },
      "source": [
        "\n",
        "# **Neural machine translation with attention**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOmKqHsl7dhS"
      },
      "source": [
        "This notebook trains a sequence to sequence (seq2seq) model for English to Deutch translation. This is an advanced example that assumes some knowledge of sequence to sequence models.\n",
        "\n",
        "After training the model in this notebook, you will be able to input English sentence, and return the Deutch translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "H7yEo84K6-sZ",
        "outputId": "9c7b10e0-9217-4067-8dd2-f26e53b69c9d"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "print(s)\n",
        "if 'K80' in s:\n",
        "    gpu = 'K80'\n",
        "elif 'T4' in s:\n",
        "    gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "    gpu = 'P100'\n",
        "else:\n",
        "    gpu='DONT PROCEED'\n",
        "display(HTML(f\"<h1>{gpu}</h1>\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 17:21:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>K80</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzASbFhOKq2W",
        "outputId": "8c689635-f719-4f78-c931-d6fa71271e69"
      },
      "source": [
        "!pip install chart-studio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chart-studio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clt4aHjH5X3G"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import string\n",
        "from string import digits\n",
        "\n",
        "import chart_studio.plotly\n",
        "import chart_studio.plotly as py\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "#%plotly.offline.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9BfTUgb73V0"
      },
      "source": [
        "##**Download and prepare the dataset**\n",
        "\n",
        "We'll use a language dataset provided by http://www.manythings.org/anki/.\n",
        "\n",
        "\n",
        "After downloading the dataset, here are the steps we'll take to prepare the data:\n",
        "\n",
        "\n",
        "1. Add a start and end token to each sentence.\n",
        "2. Clean the sentences by removing special characters.\n",
        "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "4. Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqXT5GJ06quQ",
        "outputId": "7641ac44-7bd7-442e-fed6-1c7114029b8a"
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPcgyjFCRfGx"
      },
      "source": [
        "!cp /content/drive/MyDrive/deu-eng.zip ../"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aepcrm7QR1qw",
        "outputId": "aea82ae6-9859-4e7e-a3d9-fce02ae7a28a"
      },
      "source": [
        "!unzip ../deu-eng.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ../deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybzRHiHcAoGL"
      },
      "source": [
        "file_path = 'deu.txt'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ2KBuMDAzZd",
        "outputId": "c2a19bf1-3c95-448c-8081-252d2c56815d"
      },
      "source": [
        "lines = open(file_path, encoding='UTF-8').read().strip().split('\\n')\n",
        "lines[5000:5010]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You promised.\\tSie haben es versprochen.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2549737 (CK) & #3874405 (raggione)',\n",
              " 'You scare me.\\tDu beängstigst mich.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1226152 (CK) & #2684672 (Pfirsichbaeumchen)',\n",
              " 'You scare me.\\tSie beängstigen mich.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1226152 (CK) & #2684673 (Pfirsichbaeumchen)',\n",
              " 'You scare me.\\tDu machst mir Angst.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1226152 (CK) & #2684676 (Pfirsichbaeumchen)',\n",
              " 'You stay put.\\tDu bleibst, wo du bist!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2255244 (CK) & #2671956 (freddy1)',\n",
              " 'You survived.\\tSie haben überlebt.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2549735 (CK) & #4942912 (Hans_Adler)',\n",
              " 'You survived.\\tIhr habt überlebt.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2549735 (CK) & #4942913 (Hans_Adler)',\n",
              " 'You survived.\\tDu hast überlebt.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2549735 (CK) & #4942914 (Hans_Adler)',\n",
              " \"You'll do it.\\tDu wirst es tun.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2255353 (CK) & #6626132 (Felixjp)\",\n",
              " \"You're a spy.\\tDu bist ein Spion.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2218040 (CK) & #7709184 (raggione)\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUocM7G0A3OI",
        "outputId": "f6b76831-c8fd-40f3-e829-9cb520e7f42c"
      },
      "source": [
        "print(\"total number of records: \",len(lines))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of records:  227080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr__GyO48f1c"
      },
      "source": [
        "##**Clean and Preprocess the text**\n",
        "\n",
        "1. Convert to lower case\n",
        "2. Convert special characters\n",
        "3. Remove Digits\n",
        "4. Remove spaces\n",
        "5. Add start and end tags to each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFBP3ChaDfDs"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                 if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ncK7mdB8dFb",
        "outputId": "a634c614-a5c3-4282-ff81-53aa574c9423"
      },
      "source": [
        "en_sentence = u\"How do you know what I'm thinking?\"\n",
        "deu_sentence = u\"Woher wissen Sie, was ich denke?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(deu_sentence).encode('utf-8'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> how do you know what i m thinking ? <end>\n",
            "b'<start> woher wissen sie , was ich denke ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8C8W3HiF3OH"
      },
      "source": [
        "##**Generate pairs of cleaned English and Deutch sentences with start and end added**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjdPJpzq8c9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56190f10-e54f-4080-8a00-161f05ef63ce"
      },
      "source": [
        "# Generate pairs of cleaned English and Deutch sentences\n",
        "sent_pairs = []\n",
        "#due to memory constraints we'd not be using the whole data (227080 sentences)\n",
        "for line in lines[:150000]:                                          \n",
        "    sent_pair = []\n",
        "    eng = line.rstrip().split('\\t')[0]\n",
        "    deu = line.rstrip().split('\\t')[1]\n",
        "    eng = preprocess_sentence(eng)\n",
        "    sent_pair.append(eng)\n",
        "    deu = preprocess_sentence(deu)\n",
        "    sent_pair.append(deu)\n",
        "    sent_pairs.append(sent_pair)\n",
        "sent_pairs[5000:5010]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<start> you promised . <end>', '<start> sie haben es versprochen . <end>'],\n",
              " ['<start> you scare me . <end>', '<start> du beangstigst mich . <end>'],\n",
              " ['<start> you scare me . <end>', '<start> sie beangstigen mich . <end>'],\n",
              " ['<start> you scare me . <end>', '<start> du machst mir angst . <end>'],\n",
              " ['<start> you stay put . <end>', '<start> du bleibst , wo du bist ! <end>'],\n",
              " ['<start> you survived . <end>', '<start> sie haben uberlebt . <end>'],\n",
              " ['<start> you survived . <end>', '<start> ihr habt uberlebt . <end>'],\n",
              " ['<start> you survived . <end>', '<start> du hast uberlebt . <end>'],\n",
              " ['<start> you ll do it . <end>', '<start> du wirst es tun . <end>'],\n",
              " ['<start> you re a spy . <end>', '<start> du bist ein spion . <end>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cy43B2HHLkF"
      },
      "source": [
        "##**Create a class to map every word to an index and vice-versa for any given vocabulary.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3n2TkKV8c7e"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcluJ3m8c4_"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvdQq5qICjF"
      },
      "source": [
        "##**Tokenization and Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzjMZc598c2f"
      },
      "source": [
        "def load_dataset(pairs, num_examples):\n",
        "    # pairs => already created cleaned input, output pairs\n",
        "\n",
        "    # index language using the class defined above    \n",
        "    inp_lang = LanguageIndex(en for en, de in pairs)\n",
        "    targ_lang = LanguageIndex(de for en, de in pairs)\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    # English sentences\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, de in pairs]\n",
        "    \n",
        "    # Deutch sentences\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in de.split(' ')] for en, de in pairs]\n",
        "    \n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hzdpLRE8c0L"
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(sent_pairs, len(lines))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRbEyfeiKITs"
      },
      "source": [
        "##**Creating training and validation sets using an 80-20 split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTwsYb7u8cx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f40d78-c35e-46bb-e93c-63fb192acb72"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1, random_state = 101)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135000, 135000, 15000, 15000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMSEPJrWKoPQ"
      },
      "source": [
        "##**Create a tf.data dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Q-cS278cvx"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moWKTzhhQAhr",
        "outputId": "b410e718-22d6-43da-df23-265bc5e42b11"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 14]), TensorShape([64, 24]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn8HdsApLIYe"
      },
      "source": [
        "##**Define the encoder and decoder network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obkCjaN_-ZDM"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True, \n",
        "                                   recurrent_activation='sigmoid', \n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZIwXwv88crd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856f2712-9195-41ac-8359-3fea021f16ae"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 14, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Lw4BPHBB_n"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhqqP4K08cfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37bf1eef-25ac-4a72-ce7a-71265254c170"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 21754)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oAyHIoXLxKe"
      },
      "source": [
        "## **Define the optimizer and the loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZZEm6LN8cb8"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QprXJ9h1L5Yx"
      },
      "source": [
        "## **Checkpoints (Object-based saving)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgLcJvMKL4-8"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50jlHQRiMG-O"
      },
      "source": [
        "## **Training**\n",
        "\n",
        "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
        "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
        "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
        "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "5. Use *teacher forcing* to decide the next input to the decoder.\n",
        "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
        "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6QeHuRCSGW-",
        "outputId": "a07e8d9f-0a1f-4467-ceb7-2d0f6ed99291"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every epoch\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.0951\n",
            "Epoch 1 Batch 100 Loss 1.5910\n",
            "Epoch 1 Batch 200 Loss 1.4158\n",
            "Epoch 1 Batch 300 Loss 1.3725\n",
            "Epoch 1 Batch 400 Loss 1.3298\n",
            "Epoch 1 Batch 500 Loss 1.2640\n",
            "Epoch 1 Batch 600 Loss 1.1225\n",
            "Epoch 1 Batch 700 Loss 1.1709\n",
            "Epoch 1 Batch 800 Loss 1.2205\n",
            "Epoch 1 Batch 900 Loss 1.1644\n",
            "Epoch 1 Batch 1000 Loss 1.0894\n",
            "Epoch 1 Batch 1100 Loss 1.1330\n",
            "Epoch 1 Batch 1200 Loss 1.0825\n",
            "Epoch 1 Batch 1300 Loss 1.0463\n",
            "Epoch 1 Batch 1400 Loss 1.1150\n",
            "Epoch 1 Batch 1500 Loss 0.9286\n",
            "Epoch 1 Batch 1600 Loss 0.9807\n",
            "Epoch 1 Batch 1700 Loss 0.9098\n",
            "Epoch 1 Batch 1800 Loss 0.9225\n",
            "Epoch 1 Batch 1900 Loss 0.9180\n",
            "Epoch 1 Batch 2000 Loss 0.9068\n",
            "Epoch 1 Batch 2100 Loss 0.8968\n",
            "Epoch 1 Loss 1.1342\n",
            "Time taken for 1 epoch 1630.48703789711 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.7836\n",
            "Epoch 2 Batch 100 Loss 0.7737\n",
            "Epoch 2 Batch 200 Loss 0.7651\n",
            "Epoch 2 Batch 300 Loss 0.7377\n",
            "Epoch 2 Batch 400 Loss 0.7031\n",
            "Epoch 2 Batch 500 Loss 0.7534\n",
            "Epoch 2 Batch 600 Loss 0.5929\n",
            "Epoch 2 Batch 700 Loss 0.7148\n",
            "Epoch 2 Batch 800 Loss 0.6366\n",
            "Epoch 2 Batch 900 Loss 0.6435\n",
            "Epoch 2 Batch 1000 Loss 0.5902\n",
            "Epoch 2 Batch 1100 Loss 0.6331\n",
            "Epoch 2 Batch 1200 Loss 0.5589\n",
            "Epoch 2 Batch 1300 Loss 0.6235\n",
            "Epoch 2 Batch 1400 Loss 0.5768\n",
            "Epoch 2 Batch 1500 Loss 0.4993\n",
            "Epoch 2 Batch 1600 Loss 0.5256\n",
            "Epoch 2 Batch 1700 Loss 0.5100\n",
            "Epoch 2 Batch 1800 Loss 0.5190\n",
            "Epoch 2 Batch 1900 Loss 0.6030\n",
            "Epoch 2 Batch 2000 Loss 0.4308\n",
            "Epoch 2 Batch 2100 Loss 0.4402\n",
            "Epoch 2 Loss 0.6029\n",
            "Time taken for 1 epoch 1631.550220489502 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.3900\n",
            "Epoch 3 Batch 100 Loss 0.4189\n",
            "Epoch 3 Batch 200 Loss 0.3957\n",
            "Epoch 3 Batch 300 Loss 0.3134\n",
            "Epoch 3 Batch 400 Loss 0.3734\n",
            "Epoch 3 Batch 500 Loss 0.2779\n",
            "Epoch 3 Batch 600 Loss 0.3621\n",
            "Epoch 3 Batch 700 Loss 0.3445\n",
            "Epoch 3 Batch 800 Loss 0.3701\n",
            "Epoch 3 Batch 900 Loss 0.3916\n",
            "Epoch 3 Batch 1000 Loss 0.3093\n",
            "Epoch 3 Batch 1100 Loss 0.3879\n",
            "Epoch 3 Batch 1200 Loss 0.4410\n",
            "Epoch 3 Batch 1300 Loss 0.2992\n",
            "Epoch 3 Batch 1400 Loss 0.3514\n",
            "Epoch 3 Batch 1500 Loss 0.3467\n",
            "Epoch 3 Batch 1600 Loss 0.3755\n",
            "Epoch 3 Batch 1700 Loss 0.3994\n",
            "Epoch 3 Batch 1800 Loss 0.3065\n",
            "Epoch 3 Batch 1900 Loss 0.2939\n",
            "Epoch 3 Batch 2000 Loss 0.3520\n",
            "Epoch 3 Batch 2100 Loss 0.3926\n",
            "Epoch 3 Loss 0.3591\n",
            "Time taken for 1 epoch 1631.91259598732 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2244\n",
            "Epoch 4 Batch 100 Loss 0.2546\n",
            "Epoch 4 Batch 200 Loss 0.2230\n",
            "Epoch 4 Batch 300 Loss 0.2627\n",
            "Epoch 4 Batch 400 Loss 0.2699\n",
            "Epoch 4 Batch 500 Loss 0.2092\n",
            "Epoch 4 Batch 600 Loss 0.2624\n",
            "Epoch 4 Batch 700 Loss 0.3205\n",
            "Epoch 4 Batch 800 Loss 0.2287\n",
            "Epoch 4 Batch 900 Loss 0.3209\n",
            "Epoch 4 Batch 1000 Loss 0.2570\n",
            "Epoch 4 Batch 1100 Loss 0.2163\n",
            "Epoch 4 Batch 1200 Loss 0.3004\n",
            "Epoch 4 Batch 1300 Loss 0.2526\n",
            "Epoch 4 Batch 1400 Loss 0.3238\n",
            "Epoch 4 Batch 1500 Loss 0.2437\n",
            "Epoch 4 Batch 1600 Loss 0.2536\n",
            "Epoch 4 Batch 1700 Loss 0.2138\n",
            "Epoch 4 Batch 1800 Loss 0.2599\n",
            "Epoch 4 Batch 1900 Loss 0.3107\n",
            "Epoch 4 Batch 2000 Loss 0.2416\n",
            "Epoch 4 Batch 2100 Loss 0.2647\n",
            "Epoch 4 Loss 0.2546\n",
            "Time taken for 1 epoch 1628.949965953827 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1554\n",
            "Epoch 5 Batch 100 Loss 0.1589\n",
            "Epoch 5 Batch 200 Loss 0.1766\n",
            "Epoch 5 Batch 300 Loss 0.1968\n",
            "Epoch 5 Batch 400 Loss 0.2226\n",
            "Epoch 5 Batch 500 Loss 0.2150\n",
            "Epoch 5 Batch 600 Loss 0.2108\n",
            "Epoch 5 Batch 700 Loss 0.1562\n",
            "Epoch 5 Batch 800 Loss 0.1621\n",
            "Epoch 5 Batch 900 Loss 0.2151\n",
            "Epoch 5 Batch 1000 Loss 0.2164\n",
            "Epoch 5 Batch 1100 Loss 0.2487\n",
            "Epoch 5 Batch 1200 Loss 0.2320\n",
            "Epoch 5 Batch 1300 Loss 0.2542\n",
            "Epoch 5 Batch 1400 Loss 0.1343\n",
            "Epoch 5 Batch 1500 Loss 0.2103\n",
            "Epoch 5 Batch 1600 Loss 0.2257\n",
            "Epoch 5 Batch 1700 Loss 0.2011\n",
            "Epoch 5 Batch 1800 Loss 0.2549\n",
            "Epoch 5 Batch 1900 Loss 0.2145\n",
            "Epoch 5 Batch 2000 Loss 0.2015\n",
            "Epoch 5 Batch 2100 Loss 0.2112\n",
            "Epoch 5 Loss 0.1972\n",
            "Time taken for 1 epoch 1651.4566361904144 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1687\n",
            "Epoch 6 Batch 100 Loss 0.1498\n",
            "Epoch 6 Batch 200 Loss 0.1616\n",
            "Epoch 6 Batch 300 Loss 0.1451\n",
            "Epoch 6 Batch 400 Loss 0.1123\n",
            "Epoch 6 Batch 500 Loss 0.1218\n",
            "Epoch 6 Batch 600 Loss 0.1131\n",
            "Epoch 6 Batch 700 Loss 0.1709\n",
            "Epoch 6 Batch 800 Loss 0.1765\n",
            "Epoch 6 Batch 900 Loss 0.2033\n",
            "Epoch 6 Batch 1000 Loss 0.1512\n",
            "Epoch 6 Batch 1100 Loss 0.1604\n",
            "Epoch 6 Batch 1200 Loss 0.1842\n",
            "Epoch 6 Batch 1300 Loss 0.1994\n",
            "Epoch 6 Batch 1400 Loss 0.1347\n",
            "Epoch 6 Batch 1500 Loss 0.1958\n",
            "Epoch 6 Batch 1600 Loss 0.1712\n",
            "Epoch 6 Batch 1700 Loss 0.1525\n",
            "Epoch 6 Batch 1800 Loss 0.1841\n",
            "Epoch 6 Batch 1900 Loss 0.1910\n",
            "Epoch 6 Batch 2000 Loss 0.1582\n",
            "Epoch 6 Batch 2100 Loss 0.1974\n",
            "Epoch 6 Loss 0.1628\n",
            "Time taken for 1 epoch 1649.0246217250824 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1256\n",
            "Epoch 7 Batch 100 Loss 0.1103\n",
            "Epoch 7 Batch 200 Loss 0.1356\n",
            "Epoch 7 Batch 300 Loss 0.0940\n",
            "Epoch 7 Batch 400 Loss 0.1627\n",
            "Epoch 7 Batch 500 Loss 0.1228\n",
            "Epoch 7 Batch 600 Loss 0.1362\n",
            "Epoch 7 Batch 700 Loss 0.1313\n",
            "Epoch 7 Batch 800 Loss 0.1426\n",
            "Epoch 7 Batch 900 Loss 0.1513\n",
            "Epoch 7 Batch 1000 Loss 0.1511\n",
            "Epoch 7 Batch 1100 Loss 0.1308\n",
            "Epoch 7 Batch 1200 Loss 0.1353\n",
            "Epoch 7 Batch 1300 Loss 0.1569\n",
            "Epoch 7 Batch 1400 Loss 0.1456\n",
            "Epoch 7 Batch 1500 Loss 0.1477\n",
            "Epoch 7 Batch 1600 Loss 0.1436\n",
            "Epoch 7 Batch 1700 Loss 0.1445\n",
            "Epoch 7 Batch 1800 Loss 0.1372\n",
            "Epoch 7 Batch 1900 Loss 0.1407\n",
            "Epoch 7 Batch 2000 Loss 0.1732\n",
            "Epoch 7 Batch 2100 Loss 0.1645\n",
            "Epoch 7 Loss 0.1397\n",
            "Time taken for 1 epoch 1635.7697732448578 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0891\n",
            "Epoch 8 Batch 100 Loss 0.0852\n",
            "Epoch 8 Batch 200 Loss 0.0864\n",
            "Epoch 8 Batch 300 Loss 0.1424\n",
            "Epoch 8 Batch 400 Loss 0.1051\n",
            "Epoch 8 Batch 500 Loss 0.0856\n",
            "Epoch 8 Batch 600 Loss 0.1262\n",
            "Epoch 8 Batch 700 Loss 0.1130\n",
            "Epoch 8 Batch 800 Loss 0.1129\n",
            "Epoch 8 Batch 900 Loss 0.1271\n",
            "Epoch 8 Batch 1000 Loss 0.1333\n",
            "Epoch 8 Batch 1100 Loss 0.1059\n",
            "Epoch 8 Batch 1200 Loss 0.1077\n",
            "Epoch 8 Batch 1300 Loss 0.1304\n",
            "Epoch 8 Batch 1400 Loss 0.1219\n",
            "Epoch 8 Batch 1500 Loss 0.1377\n",
            "Epoch 8 Batch 1600 Loss 0.1575\n",
            "Epoch 8 Batch 1700 Loss 0.1574\n",
            "Epoch 8 Batch 1800 Loss 0.1339\n",
            "Epoch 8 Batch 1900 Loss 0.1431\n",
            "Epoch 8 Batch 2000 Loss 0.1748\n",
            "Epoch 8 Batch 2100 Loss 0.1515\n",
            "Epoch 8 Loss 0.1236\n",
            "Time taken for 1 epoch 1616.7039337158203 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0914\n",
            "Epoch 9 Batch 100 Loss 0.0785\n",
            "Epoch 9 Batch 200 Loss 0.0968\n",
            "Epoch 9 Batch 300 Loss 0.0925\n",
            "Epoch 9 Batch 400 Loss 0.0971\n",
            "Epoch 9 Batch 500 Loss 0.1134\n",
            "Epoch 9 Batch 600 Loss 0.1207\n",
            "Epoch 9 Batch 700 Loss 0.0763\n",
            "Epoch 9 Batch 800 Loss 0.1288\n",
            "Epoch 9 Batch 900 Loss 0.1061\n",
            "Epoch 9 Batch 1000 Loss 0.1222\n",
            "Epoch 9 Batch 1100 Loss 0.1030\n",
            "Epoch 9 Batch 1200 Loss 0.0814\n",
            "Epoch 9 Batch 1300 Loss 0.1155\n",
            "Epoch 9 Batch 1400 Loss 0.1399\n",
            "Epoch 9 Batch 1500 Loss 0.1266\n",
            "Epoch 9 Batch 1600 Loss 0.1561\n",
            "Epoch 9 Batch 1700 Loss 0.1277\n",
            "Epoch 9 Batch 1800 Loss 0.1351\n",
            "Epoch 9 Batch 1900 Loss 0.1046\n",
            "Epoch 9 Batch 2000 Loss 0.1635\n",
            "Epoch 9 Batch 2100 Loss 0.1251\n",
            "Epoch 9 Loss 0.1110\n",
            "Time taken for 1 epoch 1617.863461971283 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0772\n",
            "Epoch 10 Batch 100 Loss 0.0803\n",
            "Epoch 10 Batch 200 Loss 0.0784\n",
            "Epoch 10 Batch 300 Loss 0.0792\n",
            "Epoch 10 Batch 400 Loss 0.0683\n",
            "Epoch 10 Batch 500 Loss 0.0954\n",
            "Epoch 10 Batch 600 Loss 0.1112\n",
            "Epoch 10 Batch 700 Loss 0.0815\n",
            "Epoch 10 Batch 800 Loss 0.0973\n",
            "Epoch 10 Batch 900 Loss 0.0966\n",
            "Epoch 10 Batch 1000 Loss 0.1186\n",
            "Epoch 10 Batch 1100 Loss 0.0855\n",
            "Epoch 10 Batch 1200 Loss 0.1142\n",
            "Epoch 10 Batch 1300 Loss 0.1297\n",
            "Epoch 10 Batch 1400 Loss 0.0971\n",
            "Epoch 10 Batch 1500 Loss 0.1183\n",
            "Epoch 10 Batch 1600 Loss 0.1109\n",
            "Epoch 10 Batch 1700 Loss 0.0893\n",
            "Epoch 10 Batch 1800 Loss 0.1086\n",
            "Epoch 10 Batch 1900 Loss 0.1273\n",
            "Epoch 10 Batch 2000 Loss 0.1098\n",
            "Epoch 10 Batch 2100 Loss 0.1163\n",
            "Epoch 10 Loss 0.1021\n",
            "Time taken for 1 epoch 1612.5402390956879 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L42AcfdgMhk3"
      },
      "source": [
        "##**Inference and Testing**\n",
        "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the *end token*.\n",
        "* And store the *attention weights for every time step*.\n",
        "\n",
        "Note: The encoder output is calculated only once for one input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX0m5sYhCyEi"
      },
      "source": [
        "def evaluate(inputs, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    \n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = ''\n",
        "    for i in inputs[0]:\n",
        "        if i == 0:\n",
        "            break\n",
        "        sentence = sentence + inp_lang.idx2word[i] + ' '\n",
        "    sentence = sentence[:-1]\n",
        "    \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwuusVPC6nz"
      },
      "source": [
        "def predict_random_val_sentence():\n",
        "    actual_sent = ''\n",
        "    k = np.random.randint(len(input_tensor_val))\n",
        "    random_input = input_tensor_val[k]\n",
        "    random_output = target_tensor_val[k]\n",
        "    random_input = np.expand_dims(random_input,0)\n",
        "    result, sentence, attention_plot = evaluate(random_input, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    print('Input: {}'.format(sentence[8:-6]))\n",
        "    print('Predicted translation: {}'.format(result[:-6]))\n",
        "    for i in random_output:\n",
        "        if i == 0:\n",
        "            break\n",
        "        actual_sent = actual_sent + targ_lang.idx2word[i] + ' '\n",
        "    actual_sent = actual_sent[8:-7]\n",
        "    print('Actual translation: {}'.format(actual_sent))\n",
        "    attention_plot = attention_plot[:len(result.split(' '))-2, 1:len(sentence.split(' '))-1]\n",
        "    sentence, result = sentence.split(' '), result.split(' ')\n",
        "    sentence = sentence[1:-1]\n",
        "    result = result[:-2]\n",
        "\n",
        "    # use plotly to generate the heat map\n",
        "    trace = go.Heatmap(z = attention_plot, x = sentence, y = result, colorscale='greens')\n",
        "    data=[trace]\n",
        "    iplot(data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO5ervCXM4aK"
      },
      "source": [
        "##**Restore the latest checkpoint and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRqS6MfxM1hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af9d7d9-436d-4acd-d1f3-964fbf28110c"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5509979bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTrumN-C-Hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "a7795b2c-98fe-4a3b-e395-3a94f2ddb953"
      },
      "source": [
        "predict_random_val_sentence()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: they need me .\n",
            "Predicted translation: sie brauchen mich . \n",
            "Actual translation: sie brauchen mich .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"57c728f3-afa6-4e06-81f1-0c0260c8f1e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"57c728f3-afa6-4e06-81f1-0c0260c8f1e4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '57c728f3-afa6-4e06-81f1-0c0260c8f1e4',\n",
              "                        [{\"colorscale\": [[0.0, \"rgb(247,252,245)\"], [0.125, \"rgb(229,245,224)\"], [0.25, \"rgb(199,233,192)\"], [0.375, \"rgb(161,217,155)\"], [0.5, \"rgb(116,196,118)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,139,69)\"], [0.875, \"rgb(0,109,44)\"], [1.0, \"rgb(0,68,27)\"]], \"type\": \"heatmap\", \"x\": [\"they\", \"need\", \"me\", \".\"], \"y\": [\"sie\", \"brauchen\", \"mich\", \".\"], \"z\": [[0.12143982946872711, 0.4312652349472046, 0.11608599126338959, 0.05037505924701691], [0.031387217342853546, 0.43287041783332825, 0.12798716127872467, 0.02514415793120861], [0.24628035724163055, 0.018539465963840485, 0.35649779438972473, 0.15402258932590485], [0.33589866757392883, 0.10053253173828125, 0.044570643454790115, 0.22283688187599182]]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('57c728f3-afa6-4e06-81f1-0c0260c8f1e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li4hwhkzC_85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "39b79360-1bd8-4eb3-d773-4274b7055249"
      },
      "source": [
        "predict_random_val_sentence()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: is it yours ?\n",
            "Predicted translation: ist es dir ? \n",
            "Actual translation: ist es ihres ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c268e23b-8021-49be-958e-7e78a2c92153\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c268e23b-8021-49be-958e-7e78a2c92153\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c268e23b-8021-49be-958e-7e78a2c92153',\n",
              "                        [{\"colorscale\": [[0.0, \"rgb(247,252,245)\"], [0.125, \"rgb(229,245,224)\"], [0.25, \"rgb(199,233,192)\"], [0.375, \"rgb(161,217,155)\"], [0.5, \"rgb(116,196,118)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,139,69)\"], [0.875, \"rgb(0,109,44)\"], [1.0, \"rgb(0,68,27)\"]], \"type\": \"heatmap\", \"x\": [\"is\", \"it\", \"yours\", \"?\"], \"y\": [\"ist\", \"es\", \"dir\", \"?\"], \"z\": [[0.05805320292711258, 0.09113217890262604, 0.061480384320020676, 0.03422332555055618], [0.15003009140491486, 0.2600855231285095, 0.2932756543159485, 0.08629461377859116], [0.14648756384849548, 0.08857589215040207, 0.3315998613834381, 0.23104558885097504], [0.23951278626918793, 0.020861122757196426, 0.1331854611635208, 0.2588071823120117]]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c268e23b-8021-49be-958e-7e78a2c92153');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20qtSdNFC_5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "17cc7851-a550-46c1-b10a-beb8f897198b"
      },
      "source": [
        "predict_random_val_sentence()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: i m glad you re safe .\n",
            "Predicted translation: ich freue mich , dass du in sicherheit bist . \n",
            "Actual translation: ich bin froh , dass ihr in sicherheit seid .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"6ea03b89-3fb0-48a2-9873-03b33703c5af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"6ea03b89-3fb0-48a2-9873-03b33703c5af\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '6ea03b89-3fb0-48a2-9873-03b33703c5af',\n",
              "                        [{\"colorscale\": [[0.0, \"rgb(247,252,245)\"], [0.125, \"rgb(229,245,224)\"], [0.25, \"rgb(199,233,192)\"], [0.375, \"rgb(161,217,155)\"], [0.5, \"rgb(116,196,118)\"], [0.625, \"rgb(65,171,93)\"], [0.75, \"rgb(35,139,69)\"], [0.875, \"rgb(0,109,44)\"], [1.0, \"rgb(0,68,27)\"]], \"type\": \"heatmap\", \"x\": [\"i\", \"m\", \"glad\", \"you\", \"re\", \"safe\", \".\"], \"y\": [\"ich\", \"freue\", \"mich\", \",\", \"dass\", \"du\", \"in\", \"sicherheit\", \"bist\", \".\"], \"z\": [[0.02659972570836544, 0.275115042924881, 0.2617400288581848, 0.1974828839302063, 0.07967948168516159, 0.017872938886284828, 0.012989782728254795], [0.006028438452631235, 0.227105513215065, 0.25235697627067566, 0.13462616503238678, 0.0394182987511158, 0.013536939397454262, 0.00988380704075098], [0.21226748824119568, 0.00996260903775692, 0.4206065833568573, 0.18225228786468506, 0.014398327097296715, 0.010682914406061172, 0.003955259453505278], [0.2747778296470642, 0.15968869626522064, 0.16932599246501923, 0.21894332766532898, 0.059270795434713364, 0.03640145808458328, 0.02247527241706848], [0.2675663232803345, 0.040315765887498856, 0.05779808387160301, 0.11372330039739609, 0.0938466414809227, 0.18093927204608917, 0.10797998309135437], [0.04575769975781441, 0.03640663996338844, 0.018539465963840485, 0.020502157509326935, 0.35550516843795776, 0.21492332220077515, 0.08256392925977707], [0.0813770666718483, 0.00777007732540369, 0.01522392313927412, 0.01783854514360428, 0.03502223268151283, 0.5106534361839294, 0.1600014716386795], [0.05034002289175987, 0.005885295104235411, 0.011976517736911774, 0.01183694414794445, 0.060686804354190826, 0.2521958649158478, 0.18276308476924896], [0.026505298912525177, 0.01308934111148119, 0.010171635076403618, 0.019689802080392838, 0.1659051775932312, 0.14313670992851257, 0.07233508676290512], [0.30330178141593933, 0.04475485160946846, 0.008624312467873096, 0.015633201226592064, 0.04374003782868385, 0.05841407924890518, 0.10280700027942657]]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6ea03b89-3fb0-48a2-9873-03b33703c5af');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zH16eZu3ntp"
      },
      "source": [
        "import  nltk.translate.bleu_score as bleu"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90C-Jo_Z3nq4"
      },
      "source": [
        "reference_translation='ist es ihres ?'.split()\n",
        "candidate_translation='ist es dir ?'.split()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K00K_EYy3no9",
        "outputId": "b319b1ab-2528-49b6-a2d1-705a2b45c5c8"
      },
      "source": [
        "print(\"BLEU Score: \",bleu.sentence_bleu(reference_translation, candidate_translation))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU Score:  0.7071067811865476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIKcC5F3nmV",
        "outputId": "eecd5ab6-400c-49e1-980a-74af1a8d7e82"
      },
      "source": [
        "# 4-gram cumulative BLEU\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = ' ich bin froh , dass ihr in sicherheit seid .'.split()\n",
        "candidate = ' ich freue mich , dass du in sicherheit bist .'.split()\n",
        "score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "print(score)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.668740304976422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKLegh-03ncc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHGoNnKr3nNV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}